---
title: WASSA and EMNLP 2018
---

Just back from presenting a paper on topic and opinion detection<sup>1</sup> at WASSA 2018 which was part of this years EMNLP, my fist time attending that, second at an ACL event and fourth overall big conference. 

Here are some thoughts.

<h2>Venue</h2>

Both the conference and the workshop took place at Square, a conference centre right in the centre of town. Considering the massive amount of attendees (c. 2,500), they didn't do to bad a job of organising everything  Coffee break snacks were not up to LREC 2018 standards, but then that was Japan.

One area where organisation broke down a little was in the poster sessions – more on that later.

The view from the 3rd floor:
![Square and Brussels](/assets/brussels.jpg)

Another thing was security, which noone seemed to be bothered about at any other conference I've been to. Here there were bag searches on every entry. I think this may be a Belgium thing.


<h2>WASSA</h2>

Despite some ongoing technical hitches with the screens, the workshop opened with an invited talk by Elen Riloff on identifying affective events and the reasons for their polarity. She suggested that around 40% of events have affective polarity, and presented work on classifying these according to a set of 'human needs', such as physiological, health & safety, financial and social needs.

Following this were the paper presentations, of which the interesting points for me were the following:

The first of many mentions this week of AllenNLP's ELMo word embeddings tool in Ilić et al.'s sarcasm detection paper.<sup>2</sup>

Somewhat similar to the aims of my project, Bhatia and P used LDA and sentiment analysis to perform 'topic specific sentiment analysis' in attempt to identify the political ideology members of Congress. Why wouldn't LDA work for me again? Because LDA tends to discover neutral topics rather that policies to which one might have an opinion. Here they use party labels to represent ideology, but, in our case at least, we're not interested in predicting party affiliation – we already know it. Want we want to find out is *within-party* variation on policy topics, so the approaches used here are not really suitable.


<h3>References</h3>
In Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis.
Association for Computational Linguistics:
1. Abercrombie, G. and Batista-Navarro, R. 2018. Identifying Opinion-Topics and Polarity of Parliamentary Debate Motions. 
2. Ilić, S., Marrese-Taylor, E., Balazs, J.A. and Matsuo, Y., 2018. Deep contextualized word representations for detecting sarcasm and irony.
